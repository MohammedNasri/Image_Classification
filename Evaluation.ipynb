{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "conIznwF4D6g"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import sys, random\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OR7sytqc4QYt",
    "outputId": "8489b40c-184b-4f12-d58c-47cf9887deec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Mu-QPYPk4beI"
   },
   "outputs": [],
   "source": [
    "def extract_zip_file(zip_path, dest_path):\n",
    "    \"\"\"\n",
    "    This function extracts a zip file to a specified destination path.\n",
    "\n",
    "    Parameters:\n",
    "    zip_path (str): The path to the zip file that needs to be extracted.\n",
    "    dest_path (str): The path where the zip file should be extracted to.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Open the zip file in read mode\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Extract all the contents of the zip file to dest_path\n",
    "        zip_ref.extractall(dest_path)\n",
    "\n",
    "# Usage\n",
    "# The function is called with the path of the zip file and the destination path as arguments\n",
    "extract_zip_file('/content/drive/MyDrive/data.zip', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "u8K_D-_m5Nju"
   },
   "outputs": [],
   "source": [
    "# Path for model\n",
    "MODEL = '/content/drive/MyDrive/model_finetune.pth'\n",
    "CSV_FILE = \"/content/data/X_test.csv\"\n",
    "OUTPUT_FILE = \"/content/data/submission_finetune.csv\"\n",
    "\n",
    "# Load the model for testing\n",
    "model = torch.load(MODEL)\n",
    "model.eval()\n",
    "\n",
    "# Class labels for prediction\n",
    "class_names = ['0', '1']\n",
    "\n",
    "# Preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Enable gpu mode, if cuda available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Create a new DataFrame for the output\n",
    "output_df = pd.DataFrame(columns=['output'])\n",
    "\n",
    "# Perform prediction for each image in the CSV file\n",
    "with torch.no_grad():\n",
    "    for index, row in df.iterrows():\n",
    "        img_path = Path(row['image_path']).resolve()\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        inputs = preprocess(img).unsqueeze(0).to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        output_df.loc[index, 'output'] = class_names[preds.item()]\n",
    "\n",
    "# Save the output DataFrame to a new CSV file\n",
    "output_df.to_csv(OUTPUT_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xkY9K2CV-ahN"
   },
   "outputs": [],
   "source": [
    "def vgg_block_single(in_ch, out_ch, kernel_size=3, padding=1):\n",
    "    \"\"\"\n",
    "    This function defines a single convolutional block for VGG network.\n",
    "\n",
    "    Parameters:\n",
    "    in_ch (int): The number of input channels.\n",
    "    out_ch (int): The number of output channels.\n",
    "    kernel_size (int): The size of the kernel. Default is 3.\n",
    "    padding (int): The size of the padding. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    nn.Sequential: A sequential container of Conv2d, ReLU, and MaxPool2d.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding),  # Convolutional layer\n",
    "        nn.ReLU(),  # Activation function\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling layer\n",
    "    )\n",
    "\n",
    "def vgg_block_double(in_ch, out_ch, kernel_size=3, padding=1):\n",
    "    \"\"\"\n",
    "    This function defines a double convolutional block for VGG network.\n",
    "\n",
    "    Parameters:\n",
    "    in_ch (int): The number of input channels.\n",
    "    out_ch (int): The number of output channels.\n",
    "    kernel_size (int): The size of the kernel. Default is 3.\n",
    "    padding (int): The size of the padding. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    nn.Sequential: A sequential container of two Conv2d, two ReLU, and one MaxPool2d.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding),  # First convolutional layer\n",
    "        nn.ReLU(),  # First activation function\n",
    "        nn.Conv2d(out_ch, out_ch, kernel_size=kernel_size, padding=padding),  # Second convolutional layer\n",
    "        nn.ReLU(),  # Second activation function\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling layer\n",
    "    )\n",
    "\n",
    "class MyVGG11(nn.Module):\n",
    "    \"\"\"\n",
    "    This class defines the VGG11 architecture.\n",
    "\n",
    "    Attributes:\n",
    "    conv_block1 (nn.Sequential): The first convolutional block.\n",
    "    conv_block2 (nn.Sequential): The second convolutional block.\n",
    "    conv_block3 (nn.Sequential): The third convolutional block.\n",
    "    conv_block4 (nn.Sequential): The fourth convolutional block.\n",
    "    conv_block5 (nn.Sequential): The fifth convolutional block.\n",
    "    fc_layers (nn.Sequential): The fully connected layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the convolutional blocks\n",
    "        self.conv_block1 = vgg_block_single(in_ch, 64)\n",
    "        self.conv_block2 = vgg_block_single(64, 128)\n",
    "        self.conv_block3 = vgg_block_double(128, 256)\n",
    "        self.conv_block4 = vgg_block_double(256, 512)\n",
    "        self.conv_block5 = vgg_block_double(512, 512)\n",
    "\n",
    "        # Define the fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),  # First fully connected layer\n",
    "            nn.ReLU(inplace=True),  # Activation function\n",
    "            nn.Dropout(),  # Dropout layer\n",
    "            nn.Linear(4096, 4096),  # Second fully connected layer\n",
    "            nn.ReLU(inplace=True),  # Activation function\n",
    "            nn.Dropout(),  # Dropout layer\n",
    "            nn.Linear(4096, num_classes)  # Output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of the VGG11 network.\n",
    "\n",
    "        Parameters:\n",
    "        x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: The output tensor.\n",
    "        \"\"\"\n",
    "        # Pass the input through the convolutional blocks\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.conv_block5(x)\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Pass the flattened tensor through the fully connected layers\n",
    "        x = self.fc_layers(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xM27B-DB7jHK"
   },
   "outputs": [],
   "source": [
    "# Define the path for the model, input CSV file, and output CSV file\n",
    "MODEL = '/content/drive/MyDrive/model_scratch.pth'\n",
    "CSV_FILE = \"/content/data/X_test.csv\"\n",
    "OUTPUT_FILE = \"/content/data/submission_scratch.csv\"\n",
    "\n",
    "# Load the model for testing\n",
    "model = torch.load(MODEL)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the class labels for prediction\n",
    "class_names = ['0', '1']\n",
    "\n",
    "# Define the preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(size=256),  # Resize the image\n",
    "    transforms.CenterCrop(size=224),  # Crop the image from the center\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "# Enable GPU mode, if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Create a new DataFrame for the output\n",
    "output_df = pd.DataFrame(columns=['output'])\n",
    "\n",
    "# Perform prediction for each image in the CSV file\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for index, row in df.iterrows():\n",
    "        img_path = Path(row['image_path']).resolve()  # Get the image path\n",
    "        img = Image.open(img_path).convert('RGB')  # Open the image and convert it to RGB\n",
    "        inputs = preprocess(img).unsqueeze(0).to(device)  # Preprocess the image and move it to the device\n",
    "        outputs = model(inputs)  # Get the model's predictions\n",
    "        _, preds = torch.max(outputs, 1)  # Get the predicted class\n",
    "        output_df.loc[index, 'output'] = class_names[preds.item()]  # Add the prediction to the output DataFrame\n",
    "\n",
    "# Save the output DataFrame to a new CSV file\n",
    "output_df.to_csv(OUTPUT_FILE, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqJ0I3tY-OT-"
   },
   "outputs": [],
   "source": [
    "# Define the path for the model, input CSV file, and output CSV file\n",
    "MODEL = '/content/drive/MyDrive/model_transfer.pth'\n",
    "CSV_FILE = \"/content/data/X_test.csv\"\n",
    "OUTPUT_FILE = \"/content/data/submission_transfer.csv\"\n",
    "\n",
    "# Load the model for testing\n",
    "model = torch.load(MODEL)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the class labels for prediction\n",
    "class_names = ['0', '1']\n",
    "\n",
    "# Define the preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(size=256),  # Resize the image\n",
    "    transforms.CenterCrop(size=224),  # Crop the image from the center\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "# Enable GPU mode, if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Create a new DataFrame for the output\n",
    "output_df = pd.DataFrame(columns=['output'])\n",
    "\n",
    "# Perform prediction for each image in the CSV file\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for index, row in df.iterrows():\n",
    "        img_path = Path(row['image_path']).resolve()  # Get the image path\n",
    "        img = Image.open(img_path).convert('RGB')  # Open the image and convert it to RGB\n",
    "        inputs = preprocess(img).unsqueeze(0).to(device)  # Preprocess the image and move it to the device\n",
    "        outputs = model(inputs)  # Get the model's predictions\n",
    "        _, preds = torch.max(outputs, 1)  # Get the predicted class\n",
    "        output_df.loc[index, 'output'] = class_names[preds.item()]  # Add the prediction to the output DataFrame\n",
    "\n",
    "# Save the output DataFrame to a new CSV file\n",
    "output_df.to_csv(OUTPUT_FILE, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the model, input CSV file, and output CSV file\n",
    "MODEL = '/content/drive/MyDrive/model_finetune.pth'\n",
    "CSV_FILE = \"/content/data/X_test.csv\"\n",
    "OUTPUT_FILE = \"/content/data/submission_finetune.csv\"\n",
    "\n",
    "# Load the model for testing\n",
    "model = torch.load(MODEL)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the class labels for prediction\n",
    "class_names = ['0', '1']\n",
    "\n",
    "# Define the preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(size=256),  # Resize the image\n",
    "    transforms.CenterCrop(size=224),  # Crop the image from the center\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "# Enable GPU mode, if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Create a new DataFrame for the output\n",
    "output_df = pd.DataFrame(columns=['output'])\n",
    "\n",
    "# Perform prediction for each image in the CSV file\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for index, row in df.iterrows():\n",
    "        img_path = Path(row['image_path']).resolve()  # Get the image path\n",
    "        img = Image.open(img_path).convert('RGB')  # Open the image and convert it to RGB\n",
    "        inputs = preprocess(img).unsqueeze(0).to(device)  # Preprocess the image and move it to the device\n",
    "        outputs = model(inputs)  # Get the model's predictions\n",
    "        _, preds = torch.max(outputs, 1)  # Get the predicted class\n",
    "        output_df.loc[index, 'output'] = class_names[preds.item()]  # Add the prediction to the output DataFrame\n",
    "\n",
    "# Save the output DataFrame to a new CSV file\n",
    "output_df.to_csv(OUTPUT_FILE, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
