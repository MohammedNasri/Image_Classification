{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29e94eb-83f5-4c63-81ca-0dba971b3674",
   "metadata": {
    "collapsed": true,
    "id": "d29e94eb-83f5-4c63-81ca-0dba971b3674",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "import zipfile\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import multiprocessing\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import time, os, copy, argparse\n",
    "from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gF4NHPhInv1Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gF4NHPhInv1Y",
    "outputId": "fd5eea96-db71-4369-c7aa-678f1d62df68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2c0dfb-f470-4ff2-a476-91da5efc08b6",
   "metadata": {
    "id": "ca2c0dfb-f470-4ff2-a476-91da5efc08b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_zip_file(zip_path, dest_path):\n",
    "    \"\"\"\n",
    "    This function extracts a zip file to a specified destination path.\n",
    "\n",
    "    Parameters:\n",
    "    zip_path (str): The path to the zip file that needs to be extracted.\n",
    "    dest_path (str): The path where the zip file should be extracted to.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Open the zip file in read mode\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Extract all the contents of the zip file to dest_path\n",
    "        zip_ref.extractall(dest_path)\n",
    "\n",
    "# Usage\n",
    "# The function is called with the path of the zip file and the destination path as arguments\n",
    "extract_zip_file('/content/drive/MyDrive/data.zip', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7158adb9-9a9d-4c18-89b8-bcba65e6bb81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7158adb9-9a9d-4c18-89b8-bcba65e6bb81",
    "outputId": "8614e3b4-5745-42ec-c62b-22f7998e5ff1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n",
      "0    532\n",
      "1    507\n",
      "Name: count, dtype: int64\n",
      "(1039, 16)\n",
      "(1039, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "X_train = pd.read_csv('data/X_train.csv')  # Load features from CSV file\n",
    "Y_train = pd.read_csv('data/Y_train.csv')  # Load labels from CSV file\n",
    "\n",
    "# Add the output column to X_train\n",
    "X_train['output'] = Y_train['output']  # Add 'output' column to X_train dataframe\n",
    "\n",
    "# Print the count of unique values in the 'output' column. This is useful to understand the distribution of values.\n",
    "print(X_train['output'].value_counts())\n",
    "\n",
    "# Print the shape of the dataframes to understand the number of rows and columns\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of Y_train: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163cc75c-6f52-4a48-90c1-565724edbeac",
   "metadata": {
    "id": "163cc75c-6f52-4a48-90c1-565724edbeac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "# The stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify.\n",
    "# For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "train, valid = train_test_split(X_train, test_size=0.10, stratify=X_train['output'], random_state=42)\n",
    "\n",
    "def process_df(df, folder):\n",
    "    \"\"\"\n",
    "    This function processes a dataframe and copies images to a specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The dataframe to process.\n",
    "    folder (str): The folder to copy images to.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Iterate over each row in the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Get the output value (0 or 1)\n",
    "        output = row['output']\n",
    "\n",
    "        # Create the output directory if it doesn't exist\n",
    "        output_dir = os.path.join('IMAGES_', folder, str(output))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Copy the image to the output directory\n",
    "        shutil.copy(row['image_path'], output_dir)\n",
    "\n",
    "# Process the training and validation dataframes\n",
    "process_df(train, 'train')\n",
    "process_df(valid, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f7be53-0e36-4860-b85a-ba7a6fdb85e2",
   "metadata": {
    "id": "89f7be53-0e36-4860-b85a-ba7a6fdb85e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_directory = 'IMAGES_/train'\n",
    "valid_directory = 'IMAGES_/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "feab8fb1-c627-453a-bd7f-8a80e2eb4732",
   "metadata": {
    "id": "feab8fb1-c627-453a-bd7f-8a80e2eb4732",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mode for training ('finetune' indicates that a pre-trained model will be fine-tuned)\n",
    "train_mode = 'finetune'\n",
    "\n",
    "# Path to save the fine-tuned model\n",
    "PATH = \"model_finetune.pth\"\n",
    "\n",
    "# Batch size for training\n",
    "bs = 8\n",
    "\n",
    "# Number of epochs for training\n",
    "num_epochs = 10\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Number of workers for data loading\n",
    "num_cpu = multiprocessing.cpu_count()\n",
    "\n",
    "# Define the transformations to be applied to the images\n",
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),  # Randomly resize and crop the image\n",
    "        transforms.RandomRotation(degrees=15),  # Randomly rotate the image\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "        transforms.CenterCrop(size=224),  # Crop the image from the center\n",
    "        transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),  # Resize the image\n",
    "        transforms.CenterCrop(size=224),  # Crop the image from the center\n",
    "        transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets from the specified folders and apply the transformations\n",
    "dataset = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),  # Training dataset\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])  # Validation dataset\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1908826a-b4d7-4b29-bb20-54716258ad2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1908826a-b4d7-4b29-bb20-54716258ad2d",
    "outputId": "9f647c86-d90e-4cd8-d4e1-79584a522f54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['0', '1']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the size of the training and validation datasets\n",
    "dataset_sizes = {\n",
    "    'train': len(dataset['train']),  # Size of the training dataset\n",
    "    'valid': len(dataset['valid'])  # Size of the validation dataset\n",
    "}\n",
    "\n",
    "# Create DataLoader objects for the training and validation datasets\n",
    "# These will provide batches of data to the training loop\n",
    "# They also handle shuffling and parallel data loading\n",
    "dataloaders = {\n",
    "    'train': data.DataLoader(dataset['train'], batch_size=bs, shuffle=True,\n",
    "                             num_workers=num_cpu, pin_memory=True, drop_last=True),  # DataLoader for the training data\n",
    "    'valid': data.DataLoader(dataset['valid'], batch_size=bs, shuffle=True,\n",
    "                             num_workers=num_cpu, pin_memory=True, drop_last=True)  # DataLoader for the validation data\n",
    "}\n",
    "\n",
    "# Get the class names or target labels from the training dataset\n",
    "class_names = dataset['train'].classes\n",
    "\n",
    "# Print the class names\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df79f116-4a2d-439f-88c0-23e252473f77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df79f116-4a2d-439f-88c0-23e252473f77",
    "outputId": "743385ff-12ff-47d9-9706-69b18eecee16",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set size: 935 \n",
      "Validation-set size: 104\n",
      "\n",
      "Loading resnet18 for finetuning ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the sizes of the training and validation datasets\n",
    "print(\"Training-set size:\", dataset_sizes['train'])\n",
    "print(\"Validation-set size:\", dataset_sizes['valid'])\n",
    "\n",
    "# Set the default device to GPU if it's available, otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check the training mode\n",
    "if train_mode == 'finetune':\n",
    "    # Load a pre-trained ResNet18 model\n",
    "    print(\"\\nLoading ResNet18 for fine-tuning...\\n\")\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Get the number of features in the last layer (fc layer)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "    # Modify the last layer to match the number of classes in the dataset\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "elif train_mode == 'scratch':\n",
    "    # Load a custom VGG11 model for training from scratch\n",
    "    print(\"\\nLoading VGG11 for training from scratch...\\n\")\n",
    "    model_ft = MyVGG11(in_ch=3, num_classes=2)\n",
    "\n",
    "    # Set the number of epochs to a higher value for training from scratch\n",
    "    num_epochs = 100\n",
    "\n",
    "elif train_mode == 'transfer':\n",
    "    # Load a pre-trained MobileNetV2 model for transfer learning\n",
    "    print(\"\\nLoading MobileNetV2 as feature extractor...\\n\")\n",
    "    model_ft = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "    # Freeze all the layers except the last convolution block and fully connected (fc) layers\n",
    "    for params in list(model_ft.parameters())[0:-5]:\n",
    "        params.requires_grad = False\n",
    "\n",
    "    # Get the number of features in the last layer of the classifier\n",
    "    num_ftrs = model_ft.classifier[-1].in_features\n",
    "\n",
    "    # Modify the classifier to match the number of classes in the dataset\n",
    "    model_ft.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=False),\n",
    "        nn.Linear(in_features=num_ftrs, out_features=num_classes, bias=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a911f71-bf86-4730-9600-aca603177a4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "7a911f71-bf86-4730-9600-aca603177a4d",
    "outputId": "04f3ebd1-216a-4d27-9537-294f9e2d6fa6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:-\n",
      "\n",
      "0 conv1.weight True\n",
      "1 bn1.weight True\n",
      "2 bn1.bias True\n",
      "3 layer1.0.conv1.weight True\n",
      "4 layer1.0.bn1.weight True\n",
      "5 layer1.0.bn1.bias True\n",
      "6 layer1.0.conv2.weight True\n",
      "7 layer1.0.bn2.weight True\n",
      "8 layer1.0.bn2.bias True\n",
      "9 layer1.1.conv1.weight True\n",
      "10 layer1.1.bn1.weight True\n",
      "11 layer1.1.bn1.bias True\n",
      "12 layer1.1.conv2.weight True\n",
      "13 layer1.1.bn2.weight True\n",
      "14 layer1.1.bn2.bias True\n",
      "15 layer2.0.conv1.weight True\n",
      "16 layer2.0.bn1.weight True\n",
      "17 layer2.0.bn1.bias True\n",
      "18 layer2.0.conv2.weight True\n",
      "19 layer2.0.bn2.weight True\n",
      "20 layer2.0.bn2.bias True\n",
      "21 layer2.0.downsample.0.weight True\n",
      "22 layer2.0.downsample.1.weight True\n",
      "23 layer2.0.downsample.1.bias True\n",
      "24 layer2.1.conv1.weight True\n",
      "25 layer2.1.bn1.weight True\n",
      "26 layer2.1.bn1.bias True\n",
      "27 layer2.1.conv2.weight True\n",
      "28 layer2.1.bn2.weight True\n",
      "29 layer2.1.bn2.bias True\n",
      "30 layer3.0.conv1.weight True\n",
      "31 layer3.0.bn1.weight True\n",
      "32 layer3.0.bn1.bias True\n",
      "33 layer3.0.conv2.weight True\n",
      "34 layer3.0.bn2.weight True\n",
      "35 layer3.0.bn2.bias True\n",
      "36 layer3.0.downsample.0.weight True\n",
      "37 layer3.0.downsample.1.weight True\n",
      "38 layer3.0.downsample.1.bias True\n",
      "39 layer3.1.conv1.weight True\n",
      "40 layer3.1.bn1.weight True\n",
      "41 layer3.1.bn1.bias True\n",
      "42 layer3.1.conv2.weight True\n",
      "43 layer3.1.bn2.weight True\n",
      "44 layer3.1.bn2.bias True\n",
      "45 layer4.0.conv1.weight True\n",
      "46 layer4.0.bn1.weight True\n",
      "47 layer4.0.bn1.bias True\n",
      "48 layer4.0.conv2.weight True\n",
      "49 layer4.0.bn2.weight True\n",
      "50 layer4.0.bn2.bias True\n",
      "51 layer4.0.downsample.0.weight True\n",
      "52 layer4.0.downsample.1.weight True\n",
      "53 layer4.0.downsample.1.bias True\n",
      "54 layer4.1.conv1.weight True\n",
      "55 layer4.1.bn1.weight True\n",
      "56 layer4.1.bn1.bias True\n",
      "57 layer4.1.conv2.weight True\n",
      "58 layer4.1.bn2.weight True\n",
      "59 layer4.1.bn2.bias True\n",
      "60 fc.weight True\n",
      "61 fc.bias True\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 11,177,538\n",
      "Trainable params: 11,177,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 106.00\n",
      "----------------------------------------------------------------\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Transfer the model to GPU if available\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Print the summary of the model\n",
    "print('Model Summary:-\\n')\n",
    "\n",
    "# Enumerate through the model parameters and print them\n",
    "for num, (name, param) in enumerate(model_ft.named_parameters()):\n",
    "    print(num, name, param.requires_grad)  # Print the parameter number, name, and whether it requires gradient\n",
    "\n",
    "# Use the summary function from the torchsummary package to print a detailed summary of the model\n",
    "summary(model_ft, input_size=(3, 224, 224))\n",
    "\n",
    "# Print the model architecture\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e44bc0e3-ca1e-4970-9f01-9a0f02af2b74",
   "metadata": {
    "id": "e44bc0e3-ca1e-4970-9f01-9a0f02af2b74",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "# CrossEntropyLoss is used for multi-class classification tasks\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "# Stochastic Gradient Descent (SGD) is used as the optimizer\n",
    "# The learning rate is set to 0.001 and the momentum is set to 0.9\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "# The learning rate will be reduced by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4843a46-0621-4d7a-8a8e-5dcbf7a62253",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4843a46-0621-4d7a-8a8e-5dcbf7a62253",
    "outputId": "59274de2-ee77-431a-b6c9-c0865a93e30c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:-\n",
      "\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.4994 Acc: 0.7551\n",
      "valid Loss: 0.3439 Acc: 0.8269\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.3971 Acc: 0.8289\n",
      "valid Loss: 0.3229 Acc: 0.8654\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.3961 Acc: 0.8225\n",
      "valid Loss: 0.5342 Acc: 0.8077\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.2992 Acc: 0.8684\n",
      "valid Loss: 0.4526 Acc: 0.8269\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.2699 Acc: 0.8888\n",
      "valid Loss: 0.4181 Acc: 0.8750\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.2484 Acc: 0.8984\n",
      "valid Loss: 0.4374 Acc: 0.8654\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.2434 Acc: 0.8952\n",
      "valid Loss: 0.5149 Acc: 0.8558\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2572 Acc: 0.9005\n",
      "valid Loss: 0.4959 Acc: 0.8462\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1306 Acc: 0.9433\n",
      "valid Loss: 0.4621 Acc: 0.8365\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.1162 Acc: 0.9444\n",
      "valid Loss: 0.4603 Acc: 0.8558\n",
      "\n",
      "Training complete in 7m 44s\n",
      "Best val Acc: 0.875000\n",
      "\n",
      "Saving the model...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining:-\\n\")\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=30):\n",
    "    \"\"\"\n",
    "    This function trains the model for a specified number of epochs and optimizes it.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to train.\n",
    "    criterion (torch.nn.modules.loss): The loss function.\n",
    "    optimizer (torch.optim): The optimizer.\n",
    "    scheduler (torch.optim.lr_scheduler): The learning rate scheduler.\n",
    "    num_epochs (int): The number of epochs to train the model.\n",
    "\n",
    "    Returns:\n",
    "    model (torch.nn.Module): The trained model.\n",
    "    \"\"\"\n",
    "    # Record the start time\n",
    "    since = time.time()\n",
    "\n",
    "    # Initialize the best model weights and accuracy\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Initialize the TensorBoard writer\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # Loop over the number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set the model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set the model to evaluation mode\n",
    "\n",
    "            # Initialize the running loss and correct predictions\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over the data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # Transfer the inputs and labels to the device\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass and optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Update the running loss and correct predictions\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "            # Step the scheduler if in training phase\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # Calculate the epoch loss and accuracy\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = torch.tensor(running_corrects).double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Record the training loss and accuracy for each phase in TensorBoard\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            else:\n",
    "                writer.add_scalar('Valid/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Valid/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "\n",
    "            # Deep copy the model if the current accuracy is the best\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Calculate and print the time taken for training\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "# Save the entire model\n",
    "print(\"\\nSaving the model...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bba67af5-8c16-45d0-91b2-cfcde4aa2b39",
   "metadata": {
    "id": "bba67af5-8c16-45d0-91b2-cfcde4aa2b39",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "# 'model_ft' is the trained model and 'PATH' is the location where the model will be saved\n",
    "torch.save(model_ft, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93c4aa2f-90cb-45bd-9576-8e868d3509ca",
   "metadata": {
    "id": "93c4aa2f-90cb-45bd-9576-8e868d3509ca"
   },
   "outputs": [],
   "source": [
    "PATH=\"/content/drive/MyDrive/model_finetune.pth\"\n",
    "torch.save(model_ft, PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
