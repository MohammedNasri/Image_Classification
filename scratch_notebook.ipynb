{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29e94eb-83f5-4c63-81ca-0dba971b3674",
   "metadata": {
    "collapsed": true,
    "id": "d29e94eb-83f5-4c63-81ca-0dba971b3674",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "import zipfile\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import multiprocessing\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import time, os, copy, argparse\n",
    "from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gF4NHPhInv1Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gF4NHPhInv1Y",
    "outputId": "62dc4d16-81cb-4048-f2cb-d0a642a2223e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2c0dfb-f470-4ff2-a476-91da5efc08b6",
   "metadata": {
    "id": "ca2c0dfb-f470-4ff2-a476-91da5efc08b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_zip_file(zip_path, dest_path):\n",
    "    \"\"\"\n",
    "    This function extracts a zip file to a specified destination path.\n",
    "\n",
    "    Parameters:\n",
    "    zip_path (str): The path to the zip file that needs to be extracted.\n",
    "    dest_path (str): The path where the zip file should be extracted to.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Open the zip file in read mode\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Extract all the contents of the zip file to dest_path\n",
    "        zip_ref.extractall(dest_path)\n",
    "\n",
    "# Usage\n",
    "# The function is called with the path of the zip file and the destination path as arguments\n",
    "extract_zip_file('/content/drive/MyDrive/data.zip', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7158adb9-9a9d-4c18-89b8-bcba65e6bb81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7158adb9-9a9d-4c18-89b8-bcba65e6bb81",
    "outputId": "6435a59b-70e4-43bc-a112-472884f2a330",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n",
      "0    532\n",
      "1    507\n",
      "Name: count, dtype: int64\n",
      "(1039, 16)\n",
      "(1039, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "X_train = pd.read_csv('data/X_train.csv')  # Load features from CSV file\n",
    "Y_train = pd.read_csv('data/Y_train.csv')  # Load labels from CSV file\n",
    "\n",
    "# Add the output column to X_train\n",
    "X_train['output'] = Y_train['output']  # Add 'output' column to X_train dataframe\n",
    "\n",
    "# Print the count of unique values in the 'output' column. This is useful to understand the distribution of values.\n",
    "print(X_train['output'].value_counts())\n",
    "\n",
    "# Print the shape of the dataframes to understand the number of rows and columns\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of Y_train: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163cc75c-6f52-4a48-90c1-565724edbeac",
   "metadata": {
    "id": "163cc75c-6f52-4a48-90c1-565724edbeac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "# The stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify.\n",
    "# For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "train, valid = train_test_split(X_train, test_size=0.10, stratify=X_train['output'], random_state=42)\n",
    "\n",
    "def process_df(df, folder):\n",
    "    \"\"\"\n",
    "    This function processes a dataframe and copies images to a specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The dataframe to process.\n",
    "    folder (str): The folder to copy images to.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Iterate over each row in the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Get the output value (0 or 1)\n",
    "        output = row['output']\n",
    "\n",
    "        # Create the output directory if it doesn't exist\n",
    "        output_dir = os.path.join('IMAGES_', folder, str(output))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Copy the image to the output directory\n",
    "        shutil.copy(row['image_path'], output_dir)\n",
    "\n",
    "# Process the training and validation dataframes\n",
    "process_df(train, 'train')\n",
    "process_df(valid, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bW-I_YTJnnwM",
   "metadata": {
    "id": "bW-I_YTJnnwM"
   },
   "outputs": [],
   "source": [
    "def vgg_block_single(in_ch, out_ch, kernel_size=3, padding=1):\n",
    "    \"\"\"\n",
    "    This function defines a single convolutional block for VGG network.\n",
    "\n",
    "    Parameters:\n",
    "    in_ch (int): The number of input channels.\n",
    "    out_ch (int): The number of output channels.\n",
    "    kernel_size (int): The size of the kernel. Default is 3.\n",
    "    padding (int): The size of the padding. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    nn.Sequential: A sequential container of Conv2d, ReLU, and MaxPool2d.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding),  # Convolutional layer\n",
    "        nn.ReLU(),  # Activation function\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling layer\n",
    "    )\n",
    "\n",
    "def vgg_block_double(in_ch, out_ch, kernel_size=3, padding=1):\n",
    "    \"\"\"\n",
    "    This function defines a double convolutional block for VGG network.\n",
    "\n",
    "    Parameters:\n",
    "    in_ch (int): The number of input channels.\n",
    "    out_ch (int): The number of output channels.\n",
    "    kernel_size (int): The size of the kernel. Default is 3.\n",
    "    padding (int): The size of the padding. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    nn.Sequential: A sequential container of two Conv2d, two ReLU, and one MaxPool2d.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding),  # First convolutional layer\n",
    "        nn.ReLU(),  # First activation function\n",
    "        nn.Conv2d(out_ch, out_ch, kernel_size=kernel_size, padding=padding),  # Second convolutional layer\n",
    "        nn.ReLU(),  # Second activation function\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling layer\n",
    "    )\n",
    "\n",
    "class MyVGG11(nn.Module):\n",
    "    \"\"\"\n",
    "    This class defines the VGG11 architecture.\n",
    "\n",
    "    Attributes:\n",
    "    conv_block1 (nn.Sequential): The first convolutional block.\n",
    "    conv_block2 (nn.Sequential): The second convolutional block.\n",
    "    conv_block3 (nn.Sequential): The third convolutional block.\n",
    "    conv_block4 (nn.Sequential): The fourth convolutional block.\n",
    "    conv_block5 (nn.Sequential): The fifth convolutional block.\n",
    "    fc_layers (nn.Sequential): The fully connected layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the convolutional blocks\n",
    "        self.conv_block1 = vgg_block_single(in_ch, 64)\n",
    "        self.conv_block2 = vgg_block_single(64, 128)\n",
    "        self.conv_block3 = vgg_block_double(128, 256)\n",
    "        self.conv_block4 = vgg_block_double(256, 512)\n",
    "        self.conv_block5 = vgg_block_double(512, 512)\n",
    "\n",
    "        # Define the fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),  # First fully connected layer\n",
    "            nn.ReLU(inplace=True),  # Activation function\n",
    "            nn.Dropout(),  # Dropout layer\n",
    "            nn.Linear(4096, 4096),  # Second fully connected layer\n",
    "            nn.ReLU(inplace=True),  # Activation function\n",
    "            nn.Dropout(),  # Dropout layer\n",
    "            nn.Linear(4096, num_classes)  # Output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function defines the forward pass of the VGG11 network.\n",
    "\n",
    "        Parameters:\n",
    "        x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: The output tensor.\n",
    "        \"\"\"\n",
    "        # Pass the input through the convolutional blocks\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.conv_block5(x)\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Pass the flattened tensor through the fully connected layers\n",
    "        x = self.fc_layers(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f7be53-0e36-4860-b85a-ba7a6fdb85e2",
   "metadata": {
    "id": "89f7be53-0e36-4860-b85a-ba7a6fdb85e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_directory = 'IMAGES_/train'\n",
    "valid_directory = 'IMAGES_/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feab8fb1-c627-453a-bd7f-8a80e2eb4732",
   "metadata": {
    "id": "feab8fb1-c627-453a-bd7f-8a80e2eb4732",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_mode ='scratch'\n",
    "# Path to save the fine-tuned model\n",
    "PATH = \"model_finetune.pth\"\n",
    "\n",
    "# Batch size for training\n",
    "bs = 8\n",
    "\n",
    "# Number of epochs for training\n",
    "num_epochs = 10\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Number of workers for data loading\n",
    "num_cpu = multiprocessing.cpu_count()\n",
    "\n",
    "# Define the transformations to be applied to the images\n",
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),  # Randomly resize and crop the image\n",
    "        transforms.RandomRotation(degrees=15),  # Randomly rotate the image\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "        transforms.CenterCrop(size=224),  # Crop the image from the center\n",
    "        transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),  # Resize the image\n",
    "        transforms.CenterCrop(size=224),  # Crop the image from the center\n",
    "        transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets from the specified folders and apply the transformations\n",
    "dataset = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),  # Training dataset\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])  # Validation dataset\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1908826a-b4d7-4b29-bb20-54716258ad2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1908826a-b4d7-4b29-bb20-54716258ad2d",
    "outputId": "ea0f54c0-fa17-4c63-8751-44636bcbde4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['0', '1']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the size of the training and validation datasets\n",
    "dataset_sizes = {\n",
    "    'train': len(dataset['train']),  # Size of the training dataset\n",
    "    'valid': len(dataset['valid'])  # Size of the validation dataset\n",
    "}\n",
    "\n",
    "# Create DataLoader objects for the training and validation datasets\n",
    "# These will provide batches of data to the training loop\n",
    "# They also handle shuffling and parallel data loading\n",
    "dataloaders = {\n",
    "    'train': data.DataLoader(dataset['train'], batch_size=bs, shuffle=True,\n",
    "                             num_workers=num_cpu, pin_memory=True, drop_last=True),  # DataLoader for the training data\n",
    "    'valid': data.DataLoader(dataset['valid'], batch_size=bs, shuffle=True,\n",
    "                             num_workers=num_cpu, pin_memory=True, drop_last=True)  # DataLoader for the validation data\n",
    "}\n",
    "\n",
    "# Get the class names or target labels from the training dataset\n",
    "class_names = dataset['train'].classes\n",
    "\n",
    "# Print the class names\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df79f116-4a2d-439f-88c0-23e252473f77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df79f116-4a2d-439f-88c0-23e252473f77",
    "outputId": "732532d3-0fbb-409b-c680-36ab0a362d1f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set size: 935 \n",
      "Validation-set size: 104\n",
      "\n",
      "Loading VGG11 for training from scratch ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the sizes of the training and validation datasets\n",
    "print(\"Training-set size:\", dataset_sizes['train'])\n",
    "print(\"Validation-set size:\", dataset_sizes['valid'])\n",
    "\n",
    "# Set the default device to GPU if it's available, otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check the training mode\n",
    "if train_mode == 'finetune':\n",
    "    # Load a pre-trained ResNet18 model\n",
    "    print(\"\\nLoading ResNet18 for fine-tuning...\\n\")\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Get the number of features in the last layer (fc layer)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "    # Modify the last layer to match the number of classes in the dataset\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "elif train_mode == 'scratch':\n",
    "    # Load a custom VGG11 model for training from scratch\n",
    "    print(\"\\nLoading VGG11 for training from scratch...\\n\")\n",
    "    model_ft = MyVGG11(in_ch=3, num_classes=2)\n",
    "\n",
    "    # Set the number of epochs to a higher value for training from scratch\n",
    "    num_epochs = 100\n",
    "\n",
    "elif train_mode == 'transfer':\n",
    "    # Load a pre-trained MobileNetV2 model for transfer learning\n",
    "    print(\"\\nLoading MobileNetV2 as feature extractor...\\n\")\n",
    "    model_ft = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "    # Freeze all the layers except the last convolution block and fully connected (fc) layers\n",
    "    for params in list(model_ft.parameters())[0:-5]:\n",
    "        params.requires_grad = False\n",
    "\n",
    "    # Get the number of features in the last layer of the classifier\n",
    "    num_ftrs = model_ft.classifier[-1].in_features\n",
    "\n",
    "    # Modify the classifier to match the number of classes in the dataset\n",
    "    model_ft.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=False),\n",
    "        nn.Linear(in_features=num_ftrs, out_features=num_classes, bias=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a911f71-bf86-4730-9600-aca603177a4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "7a911f71-bf86-4730-9600-aca603177a4d",
    "outputId": "858f8ed4-bbe0-48f3-93f8-7307cec27386",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:-\n",
      "\n",
      "0 conv_block1.0.weight True\n",
      "1 conv_block1.0.bias True\n",
      "2 conv_block2.0.weight True\n",
      "3 conv_block2.0.bias True\n",
      "4 conv_block3.0.weight True\n",
      "5 conv_block3.0.bias True\n",
      "6 conv_block3.2.weight True\n",
      "7 conv_block3.2.bias True\n",
      "8 conv_block4.0.weight True\n",
      "9 conv_block4.0.bias True\n",
      "10 conv_block4.2.weight True\n",
      "11 conv_block4.2.bias True\n",
      "12 conv_block5.0.weight True\n",
      "13 conv_block5.0.bias True\n",
      "14 conv_block5.2.weight True\n",
      "15 conv_block5.2.bias True\n",
      "16 fc_layers.0.weight True\n",
      "17 fc_layers.0.bias True\n",
      "18 fc_layers.3.weight True\n",
      "19 fc_layers.3.bias True\n",
      "20 fc_layers.6.weight True\n",
      "21 fc_layers.6.bias True\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-3         [-1, 64, 112, 112]               0\n",
      "            Conv2d-4        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-5        [-1, 128, 112, 112]               0\n",
      "         MaxPool2d-6          [-1, 128, 56, 56]               0\n",
      "            Conv2d-7          [-1, 256, 56, 56]         295,168\n",
      "              ReLU-8          [-1, 256, 56, 56]               0\n",
      "            Conv2d-9          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-10          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-11          [-1, 256, 28, 28]               0\n",
      "           Conv2d-12          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-13          [-1, 512, 28, 28]               0\n",
      "           Conv2d-14          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-15          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-16          [-1, 512, 14, 14]               0\n",
      "           Conv2d-17          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-18          [-1, 512, 14, 14]               0\n",
      "           Conv2d-19          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-20          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-21            [-1, 512, 7, 7]               0\n",
      "           Linear-22                 [-1, 4096]     102,764,544\n",
      "             ReLU-23                 [-1, 4096]               0\n",
      "          Dropout-24                 [-1, 4096]               0\n",
      "           Linear-25                 [-1, 4096]      16,781,312\n",
      "             ReLU-26                 [-1, 4096]               0\n",
      "          Dropout-27                 [-1, 4096]               0\n",
      "           Linear-28                    [-1, 2]           8,194\n",
      "================================================================\n",
      "Total params: 128,774,530\n",
      "Trainable params: 128,774,530\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 125.18\n",
      "Params size (MB): 491.24\n",
      "Estimated Total Size (MB): 616.99\n",
      "----------------------------------------------------------------\n",
      "MyVGG11(\n",
      "  (conv_block1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Transfer the model to GPU if available\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Print the summary of the model\n",
    "print('Model Summary:-\\n')\n",
    "\n",
    "# Enumerate through the model parameters and print them\n",
    "for num, (name, param) in enumerate(model_ft.named_parameters()):\n",
    "    print(num, name, param.requires_grad)  # Print the parameter number, name, and whether it requires gradient\n",
    "\n",
    "# Use the summary function from the torchsummary package to print a detailed summary of the model\n",
    "summary(model_ft, input_size=(3, 224, 224))\n",
    "\n",
    "# Print the model architecture\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e44bc0e3-ca1e-4970-9f01-9a0f02af2b74",
   "metadata": {
    "id": "e44bc0e3-ca1e-4970-9f01-9a0f02af2b74",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "# CrossEntropyLoss is used for multi-class classification tasks\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "# Stochastic Gradient Descent (SGD) is used as the optimizer\n",
    "# The learning rate is set to 0.001 and the momentum is set to 0.9\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "# The learning rate will be reduced by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4843a46-0621-4d7a-8a8e-5dcbf7a62253",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4843a46-0621-4d7a-8a8e-5dcbf7a62253",
    "outputId": "d38930d8-c3b8-4c7f-c478-782e1f37ab0e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:-\n",
      "\n",
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.6881 Acc: 0.4930\n",
      "valid Loss: 0.6930 Acc: 0.5096\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.6880 Acc: 0.5091\n",
      "valid Loss: 0.6930 Acc: 0.5096\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.6881 Acc: 0.5048\n",
      "valid Loss: 0.6930 Acc: 0.5096\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.6880 Acc: 0.5070\n",
      "valid Loss: 0.6930 Acc: 0.5096\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.6879 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.6879 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.6874 Acc: 0.5123\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.6879 Acc: 0.5059\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.6874 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.6874 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5112\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5059\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5048\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5059\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5112\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.6873 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5059\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5048\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5059\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5112\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.6874 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5070\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5059\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5112\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5112\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5102\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.6879 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.5112\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5112\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5112\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5112\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5091\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5080\n",
      "valid Loss: 0.6929 Acc: 0.5096\n",
      "\n",
      "Training complete in 75m 30s\n",
      "Best val Acc: 0.509615\n",
      "\n",
      "Saving the model...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining:-\\n\")\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=30):\n",
    "    \"\"\"\n",
    "    This function trains the model for a specified number of epochs and optimizes it.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to train.\n",
    "    criterion (torch.nn.modules.loss): The loss function.\n",
    "    optimizer (torch.optim): The optimizer.\n",
    "    scheduler (torch.optim.lr_scheduler): The learning rate scheduler.\n",
    "    num_epochs (int): The number of epochs to train the model.\n",
    "\n",
    "    Returns:\n",
    "    model (torch.nn.Module): The trained model.\n",
    "    \"\"\"\n",
    "    # Record the start time\n",
    "    since = time.time()\n",
    "\n",
    "    # Initialize the best model weights and accuracy\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Initialize the TensorBoard writer\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # Loop over the number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set the model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set the model to evaluation mode\n",
    "\n",
    "            # Initialize the running loss and correct predictions\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over the data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # Transfer the inputs and labels to the device\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass and optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Update the running loss and correct predictions\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "            # Step the scheduler if in training phase\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # Calculate the epoch loss and accuracy\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = torch.tensor(running_corrects).double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Record the training loss and accuracy for each phase in TensorBoard\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            else:\n",
    "                writer.add_scalar('Valid/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Valid/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "\n",
    "            # Deep copy the model if the current accuracy is the best\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Calculate and print the time taken for training\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "# Save the entire model\n",
    "print(\"\\nSaving the model...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bba67af5-8c16-45d0-91b2-cfcde4aa2b39",
   "metadata": {
    "id": "bba67af5-8c16-45d0-91b2-cfcde4aa2b39",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "# 'model_ft' is the trained model and 'PATH' is the location where the model will be saved\n",
    "torch.save(model_ft, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93c4aa2f-90cb-45bd-9576-8e868d3509ca",
   "metadata": {
    "id": "93c4aa2f-90cb-45bd-9576-8e868d3509ca"
   },
   "outputs": [],
   "source": [
    "PATH=\"/content/drive/MyDrive/model_scratch.pth\"\n",
    "torch.save(model_ft, PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
